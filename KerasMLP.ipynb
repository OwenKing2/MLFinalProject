{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183872e4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install scikeras\n",
    "#!pip install jupyter_contrib_nbextensions\n",
    "#!jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84510277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import warnings\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.layers import Input, Dense, InputLayer, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import matplotlib.pyplot as plt\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de068615",
   "metadata": {
    "code_folding": [
     0,
     11,
     38,
     50,
     80,
     108,
     140,
     148
    ]
   },
   "outputs": [],
   "source": [
    "def simplified_preprocessing(filename):\n",
    "    header = [\"train_id\", \"Sentence_1\", \"Sentence_2\", \"Output\"]\n",
    "    df = pd.read_csv(filename, sep='\\t', names=header, engine='python', encoding='utf8', error_bad_lines=False,\n",
    "                     quoting=csv.QUOTE_NONE)\n",
    "    # Make all words lowercase\n",
    "    df['Sentence_1'] = df['Sentence_1'].str.lower()\n",
    "    df['Sentence_2'] = df['Sentence_2'].str.lower()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def bleu_score(sentence1array, sentence2array):\n",
    "    features = pd.DataFrame(columns=[\"BLEU_1\", \"BLEU_2\", \"BLEU_3\", \"BLEU_4\"])\n",
    "    bleu1 = []\n",
    "    bleu2 = []\n",
    "    bleu3 = []\n",
    "    bleu4 = []\n",
    "\n",
    "    for (sentence_1, sentence_2) in itertools.zip_longest(sentence1array, sentence2array):\n",
    "        first_sentence = nltk.word_tokenize(sentence_1)\n",
    "        second_sentence = nltk.word_tokenize(sentence_2)\n",
    "        bleu1.append(nltk.translate.bleu_score.sentence_bleu([first_sentence], second_sentence,\n",
    "                                                             weights=[1]))\n",
    "        bleu2.append(nltk.translate.bleu_score.sentence_bleu([first_sentence], second_sentence,\n",
    "                                                             weights=[0.5, 0.5]))\n",
    "        bleu3.append(nltk.translate.bleu_score.sentence_bleu([first_sentence], second_sentence,\n",
    "                                                             weights=[1 / 3, 1 / 3, 1 / 3]))\n",
    "        bleu4.append(nltk.translate.bleu_score.sentence_bleu([first_sentence], second_sentence,\n",
    "                                                             weights=[1 / 4, 1 / 4, 1 / 4, 1 / 4]))\n",
    "\n",
    "    features[\"BLEU_1\"] = bleu1\n",
    "    features[\"BLEU_2\"] = bleu2\n",
    "    features[\"BLEU_3\"] = bleu3\n",
    "    features[\"BLEU_4\"] = bleu4\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def meteor_scores(sentence1array, sentence2array):\n",
    "    features = pd.DataFrame(columns=[\"METEOR\"])\n",
    "\n",
    "    meteor_score = []\n",
    "    for (sentence_1, sentence_2) in itertools.zip_longest(sentence1array, sentence2array):\n",
    "        first_sentence = nltk.word_tokenize(sentence_1)\n",
    "        second_sentence = nltk.word_tokenize(sentence_2)\n",
    "        meteor_score.append(nltk.translate.meteor_score.single_meteor_score(first_sentence, second_sentence))\n",
    "    features[\"METEOR\"] = meteor_score\n",
    "    return features\n",
    "\n",
    "\n",
    "def character_bigrams_features(sentence1array, sentence2array):\n",
    "    features = pd.DataFrame(columns=[\"CharacterBigramUnion\", \"CharacterBigramIntersection\",\n",
    "                                     \"NumCharBigrams1\", \"NumCharBigrams2\",\n",
    "                                     ])\n",
    "    bigramUnion = []\n",
    "    bigramIntersection = []\n",
    "    numbigrams1 = []\n",
    "    numbigrams2 = []\n",
    "\n",
    "    for (sentence_1, sentence_2) in itertools.zip_longest(sentence1array, sentence2array):\n",
    "        sentence_1_no_spaces = sentence_1.replace(\" \", \"\")\n",
    "        sentence_2_no_spaces = sentence_2.replace(\" \", \"\")\n",
    "        sentence_1_char_bigrams = [sentence_1_no_spaces[i:i + 2] for i in range(len(sentence_1_no_spaces) - 1)]\n",
    "        sentence_2_char_bigrams = [sentence_2_no_spaces[i:i + 2] for i in range(len(sentence_2_no_spaces) - 1)]\n",
    "        bigram_matches = 0\n",
    "        for phrase in sentence_1_char_bigrams:\n",
    "            if phrase in sentence_2_char_bigrams:\n",
    "                bigram_matches += 1\n",
    "        bigramIntersection.append(bigram_matches)\n",
    "        bigramUnion.append(len(sentence_1_char_bigrams) + len(sentence_2_char_bigrams))\n",
    "        numbigrams1.append(len(sentence_1_char_bigrams))\n",
    "        numbigrams2.append(len(sentence_2_char_bigrams))\n",
    "    features[\"CharacterBigramUnion\"] = bigramUnion\n",
    "    features[\"CharacterBigramIntersection\"] = bigramIntersection\n",
    "    features[\"NumCharBigrams1\"] = numbigrams1\n",
    "    features[\"NumCharBigrams2\"] = numbigrams2\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def word_unigram_features(sentence1array, sentence2array):\n",
    "    features = pd.DataFrame(columns=[\"SentenceUnigramUnion\", \"SentenceUnigramIntersection\",\n",
    "                                     \"NumSentUnigrams1\", \"NumSentUnigrams2\"])\n",
    "    unigramUnion = []\n",
    "    unigramIntersection = []\n",
    "    numunigrams1 = []\n",
    "    numunigrams2 = []\n",
    "\n",
    "    for (sentence_1, sentence_2) in itertools.zip_longest(sentence1array, sentence2array):\n",
    "        sentence_1_words = nltk.word_tokenize(sentence_1)\n",
    "        sentence_2_words = nltk.word_tokenize(sentence_2)\n",
    "        sentence_1_unigrams = list(nltk.ngrams(sentence_1_words, 1))\n",
    "        sentence_2_unigrams = list(nltk.ngrams(sentence_2_words, 1))\n",
    "        unigram_matches = 0\n",
    "        for phrase in sentence_1_unigrams:\n",
    "            if phrase in sentence_2_unigrams:\n",
    "                unigram_matches += 1\n",
    "        unigramIntersection.append(unigram_matches)\n",
    "        unigramUnion.append(len(sentence_1_unigrams) + len(sentence_2_unigrams))\n",
    "        numunigrams1.append(len(sentence_1_unigrams))\n",
    "        numunigrams2.append(len(sentence_2_unigrams))\n",
    "    features[\"SentenceUnigramUnion\"] = unigramUnion\n",
    "    features[\"SentenceUnigramIntersection\"] = unigramIntersection\n",
    "    features[\"NumSentUnigrams1\"] = numunigrams1\n",
    "    features[\"NumSentUnigrams2\"] = numunigrams2\n",
    "    return features\n",
    "\n",
    "\n",
    "def all_features(sentence1array, sentence2array):\n",
    "    features = pd.DataFrame(columns=[\n",
    "        \"BLEU_1\", \"BLEU_2\", \"BLEU_3\", \"BLEU_4\",\n",
    "        \"Meteor Score\",\n",
    "        \"CharacterBigramUnion\", \"CharacterBigramIntersection\", \"NumCharBigrams1\", \"NumCharBigrams2\",\n",
    "        \"SentenceUnigramUnion\", \"SentenceUnigramIntersection\", \"NumSentUnigrams1\", \"NumSentUnigrams2\",\n",
    "    ])\n",
    "    bleu_scores = bleu_score(sentence1array, sentence2array)\n",
    "\n",
    "    features[\"BLEU_1\"] = bleu_scores[\"BLEU_1\"]\n",
    "    features[\"BLEU_2\"] = bleu_scores[\"BLEU_2\"]\n",
    "    features[\"BLEU_3\"] = bleu_scores[\"BLEU_3\"]\n",
    "    features[\"BLEU_4\"] = bleu_scores[\"BLEU_4\"]\n",
    "\n",
    "    features[\"Meteor Score\"] = meteor_scores(sentence1array, sentence2array)\n",
    "\n",
    "    char_bigram = character_bigrams_features(sentence1array, sentence2array)\n",
    "    word_unigram = word_unigram_features(sentence1array, sentence2array)\n",
    "\n",
    "    features[\"CharacterBigramUnion\"] = char_bigram[\"CharacterBigramUnion\"]\n",
    "    features[\"CharacterBigramIntersection\"] = char_bigram[\"CharacterBigramIntersection\"]\n",
    "    features[\"NumCharBigrams1\"] = char_bigram[\"NumCharBigrams1\"]\n",
    "    features[\"NumCharBigrams2\"] = char_bigram[\"NumCharBigrams2\"]\n",
    "\n",
    "    features[\"SentenceUnigramUnion\"] = word_unigram[\"SentenceUnigramUnion\"]\n",
    "    features[\"SentenceUnigramIntersection\"] = word_unigram[\"SentenceUnigramIntersection\"]\n",
    "    features[\"NumSentUnigrams1\"] = word_unigram[\"NumSentUnigrams1\"]\n",
    "    features[\"NumSentUnigrams2\"] = word_unigram[\"NumSentUnigrams2\"]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')  # don't have GPU\n",
    "    return device\n",
    "\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b992497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18e7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = simplified_preprocessing(\"train_with_label.txt\")\n",
    "X = all_features(training_data[\"Sentence_1\"], training_data[\"Sentence_2\"])\n",
    "y = training_data[\"Output\"]\n",
    "\n",
    "dev_data = simplified_preprocessing(\"dev_with_label.txt\")\n",
    "Xdev = all_features(dev_data[\"Sentence_1\"], dev_data[\"Sentence_2\"])\n",
    "ydev = dev_data[\"Output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e4156f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(unit):\n",
    "  # creating the layers of the NN\n",
    "  ann = tf.keras.models.Sequential()\n",
    "  ann.add(InputLayer(input_shape=(13, )))\n",
    "  ann.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "  ann.add(Dropout(0.2))\n",
    "  ann.add(tf.keras.layers.Dense(30, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "  ann.add(Dropout(0.2))\n",
    "  ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "  sgd = SGD(learning_rate=0.1, momentum=0.9)\n",
    "  ann.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7db3f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2926 - accuracy: 0.8428\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.8885\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.8601\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.8942\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.8664\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9019\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8353\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.8987\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.8505\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.8942\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.3089 - accuracy: 0.8446\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.8905\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8558\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.8885\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.8693\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.8994\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2953 - accuracy: 0.8479\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.8955\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2976 - accuracy: 0.8436\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.8987\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2960 - accuracy: 0.8601\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.8949\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.8556\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.8962\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.8585\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.8929\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2955 - accuracy: 0.8555\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9115\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.2935 - accuracy: 0.8478\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.8974\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3042 - accuracy: 0.8391\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.8937\n",
      "63/63 [==============================] - 1s 5ms/step - loss: 0.2984 - accuracy: 0.8508\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.8936\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.8382\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.8942\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.8518\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9019\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.8535\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9058\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.8543\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.8885\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3062 - accuracy: 0.8462\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.8917\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3037 - accuracy: 0.8337\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9045\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.8625\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9045\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.8576\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.8917\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.8452\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9001\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.8560\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.8859\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8510\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9000\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3003 - accuracy: 0.8452\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9026\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.8667\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9051\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.8389\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.8937\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2996 - accuracy: 0.8430\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.8936\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8678\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.8994\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2952 - accuracy: 0.8483\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.8981\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8550\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.8955\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.8556\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.8885\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.8430\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.8929\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8625\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9006\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8564\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9122\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3005 - accuracy: 0.8564\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.8962\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2920 - accuracy: 0.8554\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.8873\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.8415\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.8974\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.8646\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.8897\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.8620\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.8987\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8507\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9032\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2967 - accuracy: 0.8542\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.8853\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8612\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8294\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.8904\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8630\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9077\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8547\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9006\n",
      "63/63 [==============================] - 2s 2ms/step - loss: 0.2854 - accuracy: 0.8575\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.8892\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.8510\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9006\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.8457\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.8994\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8452\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.8885\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2899 - accuracy: 0.8550\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9013\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.8662\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.8988\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8425\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8942\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2890 - accuracy: 0.8476\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.8962\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3132 - accuracy: 0.8471\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.8936\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8388\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2964 - accuracy: 0.8468\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.8924\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8513\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.8942\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8564\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9058\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.8548\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9013\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8553\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.8981\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.8638\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.8975\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.8617\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3016 - accuracy: 0.8391\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9026\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.8550\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.8981\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.8519\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.8994\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8529\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.8930\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.8550\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.8872\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.8600\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9045\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2742 - accuracy: 0.8667\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.8981\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.8681\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9064\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2989 - accuracy: 0.8426\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.8969\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8624\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3027 - accuracy: 0.8502\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.8994\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8611\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9045\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.8651\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9019\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.8590\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.8834\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8430\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8619\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.8910\n",
      "63/63 [==============================] - 2s 3ms/step - loss: 0.2771 - accuracy: 0.8587\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9064\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.8519\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9019\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.8678\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.8821\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8415\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.8949\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.8524\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9000\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2703 - accuracy: 0.8760\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9058\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2960 - accuracy: 0.8505\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9032\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2851 - accuracy: 0.8572\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.8905\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3171 - accuracy: 0.8390\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.8942\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2892 - accuracy: 0.8555\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2130 - accuracy: 0.8917\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.8495\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8590\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9051\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8303\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.8917\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8568\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9013\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2825 - accuracy: 0.8524\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.8910\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2950 - accuracy: 0.8443\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9058\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8454\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.8612\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.8994\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.8524\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8656\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9026\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.8402\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9032\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.8641\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.8929\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2752 - accuracy: 0.8673\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.8853\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8404\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9000\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8326\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.8949\n",
      "63/63 [==============================] - 1s 4ms/step - loss: 0.2884 - accuracy: 0.8632\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9051\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8436\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9019\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8519\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.8796\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8396\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.8949\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.3096 - accuracy: 0.8435\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.8923\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.8582\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.8968\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2925 - accuracy: 0.8503\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9019\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2847 - accuracy: 0.8529\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.8962\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.8592\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.8974\n",
      "63/63 [==============================] - 2s 3ms/step - loss: 0.2693 - accuracy: 0.8721\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9077\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2991 - accuracy: 0.8399\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.8955\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.2925 - accuracy: 0.8471\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.8968\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.8801\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.8847\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2347 - accuracy: 0.8870\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.8891\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2472 - accuracy: 0.8785\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9051\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.8827\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9026\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.8795\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9103\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2379 - accuracy: 0.8837\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.8969\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.8878\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9058\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.8800\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.8936\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.8798\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.9045\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2460 - accuracy: 0.8795\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9064\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2382 - accuracy: 0.8862\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.8930\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.8829\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.8923\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.8806\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.8955\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.8806\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.8955\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.8793\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9071\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.8798\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9052\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2340 - accuracy: 0.8894\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.8987\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.8854\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9006\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.8835\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9154\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.8814\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9096\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.9065\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2432 - accuracy: 0.8827\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9051\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.8795\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.8776\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.8779\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9128\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.8776\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9109\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2385 - accuracy: 0.8838\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9033\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.8744\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9045\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.8801\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.8808\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2435 - accuracy: 0.8752\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9090\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.8829\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9135\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2382 - accuracy: 0.8822\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9078\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2377 - accuracy: 0.8858\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.8891\n",
      "313/313 [==============================] - 2s 2ms/step - loss: 0.2443 - accuracy: 0.8806\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.8949\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.8845\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.8955\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2385 - accuracy: 0.8777\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.8936\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2384 - accuracy: 0.8870\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.9097\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.8834\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.8878\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2399 - accuracy: 0.8798\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.8923\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2334 - accuracy: 0.8830\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.8968\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.8766\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9128\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.8827\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.8783\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.8773\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9077\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2396 - accuracy: 0.8867\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.8897\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.8766\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.8929\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.8718\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9006\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2386 - accuracy: 0.8830\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9013\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.8798\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9032\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.8824\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9013\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.8776\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9083\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2432 - accuracy: 0.8790\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9109\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.8760\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.8956\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2355 - accuracy: 0.8854\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.8837\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.8987\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.8798\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.8955\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.8757\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9045\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2348 - accuracy: 0.8893\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.8981\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.8826\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9038\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.8755\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.8842\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.8805\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9058\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2357 - accuracy: 0.8837\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.8808\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8064\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2365 - accuracy: 0.8816\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.8872\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.8817\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9090\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.8834\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9167\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.8806\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.8943\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2341 - accuracy: 0.8827\n",
      "78/78 [==============================] - 1s 1ms/step - loss: 0.1886 - accuracy: 0.9064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2460 - accuracy: 0.8782\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.8994\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.8769\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.8987\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.8846\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9096\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.8772\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.8770\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.8814\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2338 - accuracy: 0.8848\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.8917\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2343 - accuracy: 0.8837\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9019\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.8803\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.8974\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.8833\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9045\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.8757\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.8827\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.8803\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9064\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.8747\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.8994\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.8808\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9007\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.8696\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9026\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.8777\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.8923\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2438 - accuracy: 0.8797\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9013\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2293 - accuracy: 0.8867\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9128\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.8811\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.8924\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.8830\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.8974\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.8824\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.8955\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.8798\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9135\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2363 - accuracy: 0.8829\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.8987\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.8801\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9020\n",
      "313/313 [==============================] - 2s 2ms/step - loss: 0.2452 - accuracy: 0.8795\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9006\n",
      "313/313 [==============================] - 2s 3ms/step - loss: 0.2372 - accuracy: 0.8858\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.8865\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2438 - accuracy: 0.8790\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.8776\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9077\n",
      "312/312 [==============================] - 1s 3ms/step - loss: 0.2388 - accuracy: 0.8813\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9007\n",
      "313/313 [==============================] - 2s 2ms/step - loss: 0.2343 - accuracy: 0.8861\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.8835\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.8885\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2460 - accuracy: 0.8813\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8833\n",
      "313/313 [==============================] - 2s 3ms/step - loss: 0.2388 - accuracy: 0.8814\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9051\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.8837\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.8860\n",
      "313/313 [==============================] - 2s 2ms/step - loss: 0.2416 - accuracy: 0.8867\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.8910\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2408 - accuracy: 0.8827\n",
      "78/78 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.8910\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.8763\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.8865\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.8809\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9090\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.8873\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9084\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.8830\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2152 - accuracy: 0.8885\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.8809\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9013\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.8765\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9109\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.8827\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9077\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.8841\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.8975\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2388 - accuracy: 0.8830\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.8942\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.8859\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.8833\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.8785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9090\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2402 - accuracy: 0.8809\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9096\n",
      "312/312 [==============================] - 1s 2ms/step - loss: 0.2378 - accuracy: 0.8878\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9090\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.8819\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.8936\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.8859\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.8891\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.8819\n",
      "78/78 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9083\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2384 - accuracy: 0.8809\n",
      "78/78 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9019\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.8768\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.8956\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8612\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9013\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.8686\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.8885\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.8668\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.8981\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.8651\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.9019\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2576 - accuracy: 0.8678\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.8956\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.8755\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.8981\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.8612\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.8936\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.8752\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9179\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.8560\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.8981\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.8721\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.8924\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.8686\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9083\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.8792\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.8806\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9167\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.8801\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9109\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.8700\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9039\n",
      "125/125 [==============================] - 2s 2ms/step - loss: 0.2559 - accuracy: 0.8779\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9064\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.8769\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2463 - accuracy: 0.8766\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.9135\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2552 - accuracy: 0.8723\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9109\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.8742\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9013\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2649 - accuracy: 0.8681\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.8929\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.8774\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.8904\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2632 - accuracy: 0.8726\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9103\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.8745\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9115\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.8737\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.8930\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.8760\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9083\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2477 - accuracy: 0.8769\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2612 - accuracy: 0.8622\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9071\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2478 - accuracy: 0.8766\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9173\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.8691\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.8802\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2536 - accuracy: 0.8758\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.8962\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2555 - accuracy: 0.8750\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9071\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.8717\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.8665\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9083\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2519 - accuracy: 0.8776\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.8898\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2602 - accuracy: 0.8697\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.8676\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.8974\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.8734\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9071\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.8657\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8655\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.8821\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2485 - accuracy: 0.8742\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.8707\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9000\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.8763\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9160\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.8725\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9090\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.8806\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.8994\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2472 - accuracy: 0.8723\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9006\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.8689\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9019\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.8761\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.9077\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8592\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.8729\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.8905\n",
      "125/125 [==============================] - 2s 2ms/step - loss: 0.2535 - accuracy: 0.8785\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9083\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.8729\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.8681\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.8917\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2516 - accuracy: 0.8717\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.8790\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9052\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.8822\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9026\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.8702\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.8981\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.8749\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9160\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.8718\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9103\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.8740\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9039\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.8769\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9064\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2539 - accuracy: 0.8771\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9026\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.8686\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.8968\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.8704\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9122\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2527 - accuracy: 0.8747\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.8949\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.8753\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.8733\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9019\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.8652\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.8736\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9064\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8604\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.8834\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.8781\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.8974\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.8673\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.8755\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.8987\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.8667\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9096\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.8679\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9013\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2626 - accuracy: 0.8691\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9006\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.8694\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9038\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.8696\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9096\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2664 - accuracy: 0.8579\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9019\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.8740\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.8879\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8640\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.8897\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.8733\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.8981\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.8702\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9077\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.8693\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9135\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2609 - accuracy: 0.8723\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.8937\n",
      "125/125 [==============================] - 2s 2ms/step - loss: 0.2639 - accuracy: 0.8693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.8765\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.8808\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.8649\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9013\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.8718\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9032\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.8707\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.9026\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.8805\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9006\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.8707\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9032\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.8701\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9058\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2647 - accuracy: 0.8656\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.9090\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.8721\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.8975\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.8800\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.8962\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.8737\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9128\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.8649\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9083\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.8768\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9071\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2601 - accuracy: 0.8639\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.8905\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.8789\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9077\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.8787\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.8840\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.8691\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9045\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.8721\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9077\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.8793\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.8994\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.8725\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.8987\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.8734\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.9038\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2488 - accuracy: 0.8792\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9000\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.8731\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9090\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.8710\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9007\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.8712\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9006\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.8691\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.8891\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.8739\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9122\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.8678\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9013\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.8734\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9052\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.8713\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9000\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.8761\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.8846\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 0.2463 - accuracy: 0.8771\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9077\n",
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8627\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.8804\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9020\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.8776\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.8885\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2349 - accuracy: 0.8866\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.8878\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.8753\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9173\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.8781\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9122\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.8744\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.8885\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.8768\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.8974\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.8811\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.8949\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.8662\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9122\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.8752\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9071\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.8819\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.8905\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.8800\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.8784\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.8942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.8801\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9064\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.8826\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.8994\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.8788\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9065\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.8822\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.8987\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.8795\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9058\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2345 - accuracy: 0.8829\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9051\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.8793\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9096\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.8758\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.8885\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.8822\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9058\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2409 - accuracy: 0.8817\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9051\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.8798\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9045\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.8840\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9103\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.8841\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.8924\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.8773\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.8891\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.8765\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9013\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.8720\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9019\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.8789\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9090\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.8846\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9058\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.8830\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9038\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2438 - accuracy: 0.8760\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.8821\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2380 - accuracy: 0.8801\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9064\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.8824\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9096\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.2363 - accuracy: 0.8859\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.8866\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.8874\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9096\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.8773\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9058\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.8798\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.9083\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.8766\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9051\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.8771\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9001\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.8723\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.8994\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.8853\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8744\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2327 - accuracy: 0.8891\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9064\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.8790\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9071\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.8792\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.8943\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.8766\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.8968\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2421 - accuracy: 0.8843\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.8782\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.8968\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2378 - accuracy: 0.8801\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9083\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2294 - accuracy: 0.8875\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.8738\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.8824\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.8968\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.8784\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.8872\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.8774\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2511 - accuracy: 0.8803\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9058\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.8801\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9103\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.8766\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.8955\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.8826\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.8929\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.8835\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9038\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.8753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.8981\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.8837\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9007\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.8721\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.8795\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.8760\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.8968\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2610 - accuracy: 0.8665\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.8872\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.8756\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9007\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.8797\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9019\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2384 - accuracy: 0.8858\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.8955\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.8797\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.9109\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2480 - accuracy: 0.8782\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9115\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.2324 - accuracy: 0.8827\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9013\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.2366 - accuracy: 0.8853\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.8981\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2429 - accuracy: 0.8747\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9006\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.8824\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9045\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.8760\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.8981\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.8803\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.8969\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.8862\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.8968\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.8745\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.8885\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2458 - accuracy: 0.8790\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9058\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.8846\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9147\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.8795\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.8924\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.8846\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9000\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.8840\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.8949\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.8782\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9115\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2460 - accuracy: 0.8782\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9083\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2352 - accuracy: 0.8841\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9001\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.8779\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9006\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.8785\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.8872\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.8859\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9006\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.8773\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9051\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.8787\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.8808\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.8811\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.8974\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2420 - accuracy: 0.8830\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9038\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.8697\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.8987\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.8797\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.8936\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.8774\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.8949\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.8806\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.8923\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.8793\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9006\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.8800\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.8929\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.8779\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9103\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.8854\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.8687\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.8765\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.8878\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.8766\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.8833\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2336 - accuracy: 0.8856\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9179\n",
      "250/250 [==============================] - 2s 2ms/step - loss: 0.2386 - accuracy: 0.8808\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9077\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.8772\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.8793\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9019\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.8782\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9026\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.8817\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.8949\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.8846\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9077\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.8817\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.8892\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2327 - accuracy: 0.8862\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9032\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.8845\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9019\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.8808\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9026\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.8763\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9103\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.8867\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.8949\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.8862\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.8987\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.8744\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.9013\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.8827\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.8917\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.8761\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9000\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2402 - accuracy: 0.8795\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.8821\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.8846\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.8974\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.8809\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.8846\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2338 - accuracy: 0.8851\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9154\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.8785\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.8865\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.8779\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.8975\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.8838\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9071\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.8758\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.8981\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.8761\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.8981\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.8766\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9083\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2378 - accuracy: 0.8795\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.8834\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.8801\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9000\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.8858\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9045\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.8771\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9006\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.8829\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9109\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.8731\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9065\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.8797\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9019\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.8801\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9038\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.8787\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9019\n",
      "196/196 [==============================] - 2s 2ms/step - loss: 0.2549 - accuracy: 0.8771\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9096\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.8838\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9058\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.8830\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9058\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.8776\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9006\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2371 - accuracy: 0.8777\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.8955\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2391 - accuracy: 0.8829\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9096\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.8801\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.8981\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.8830\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.8974\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.8739\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.8962\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.8729\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9179\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2421 - accuracy: 0.8827\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9077\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.8809\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.8937\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.8771\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.8987\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.8805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9019\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.8787\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9032\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.8749\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2188 - accuracy: 0.8949\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.8761\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.8937\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.8837\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9083\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2314 - accuracy: 0.8851\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.8987\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.8800\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.8981\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.8733\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1969 - accuracy: 0.9038\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.8833\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.8994\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2388 - accuracy: 0.8862\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.8981\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.8745\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.8769\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.8798\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.8994\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.8850\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9115\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.8768\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9013\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.8853\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.8987\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.8808\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1953 - accuracy: 0.9032\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.8776\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9096\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.8774\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9135\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2472 - accuracy: 0.8780\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.8885\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.8808\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.8917\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.8792\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.8994\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.8728\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9026\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.8854\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9058\n",
      "195/195 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.8825\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.8776\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.8758\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.8974\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.8792\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9019\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.8750\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.9090\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.8725\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.8699\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2466 - accuracy: 0.8827\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.8879\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.8845\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9051\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2371 - accuracy: 0.8819\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8846\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.8750\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9032\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.8817\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9147\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.8877\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9007\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.8821\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9013\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.8765\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.8974\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.8773\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9045\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.8761\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9115\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.8846\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.8840\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.8758\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.8897\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2400 - accuracy: 0.8809\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.8955\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.8672\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.9064\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.8747\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9103\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.8800\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.8879\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.8853\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.8949\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.8817\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.8974\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.8771\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.8737\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.8949\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.8837\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9026\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2451 - accuracy: 0.8737\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.8994\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.8808\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9000\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.8817\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.9058\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2380 - accuracy: 0.8814\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9077\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.8747\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.8860\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.8777\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.8962\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.8712\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8987\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.8774\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9077\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.8814\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.8917\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2354 - accuracy: 0.8846\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.8924\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.8806\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.8917\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.8793\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.8942\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.8808\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9077\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.8813\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9045\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.8753\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.8898\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.8785\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9000\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.8805\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9045\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.8753\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9083\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2402 - accuracy: 0.8848\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9077\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2491 - accuracy: 0.8771\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9026\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.8792\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9064\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.8720\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.8942\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.8685\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9032\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.8733\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9077\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.8768\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8885\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.8787\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9038\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.8856\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9026\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.8755\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9109\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.8765\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.8987\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.8755\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.8917\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.8906\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.8949\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.8803\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.8942\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.8758\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9103\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.8784\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9096\n",
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.8777\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.8994\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.8819\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9038\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.8862\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9019\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.8741\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.8955\n",
      "196/196 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.8704\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9051\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "# model=KerasClassifier(build_fn=build_clf)\n",
    "\n",
    "params={'mlp__batch_size':[100, 20, 50, 25, 32], \n",
    "        'mlp__nb_epoch':[200, 100, 300, 400],\n",
    "        'mlp__unit':[5,6, 10, 11, 12, 15],\n",
    "           \n",
    "        }\n",
    "\n",
    "pipe = Pipeline(steps=[('std_scl', StandardScaler()),\n",
    "                       ('mlp', KerasClassifier(build_fn=build_clf))])\n",
    "\n",
    "\n",
    "\n",
    "# estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "# estimators.append(('mlp', KerasClassifier(build_fn =build_clf, nb_epoch=300, batch_size=16, unit=5)))\n",
    "# pipeline = Pipeline(estimators)\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "# print(\"Hidden: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "# classifier.fit(X_train, y_train)\n",
    "#gs=GridSearchCV(estimator=model, param_grid=params, cv=10)\n",
    "\n",
    "gs = GridSearchCV(pipe, params)\n",
    "# now fit the dataset to the GridSearchCV object. \n",
    "gs = gs.fit(X, y)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "# print(\"Hidden: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fceea44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mlp__batch_size': 50, 'mlp__nb_epoch': 200, 'mlp__unit': 11}\n",
      "0.9078328490257264\n"
     ]
    }
   ],
   "source": [
    "best_params=gs.best_params_\n",
    "accuracy=gs.best_score_\n",
    "print(best_params)\n",
    "print(accuracy)\n",
    "#print(gs.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "965f164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step\n",
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# test_acc = gs.score(Xdev, ydev)\n",
    "# print(\"Test accuracy:\", test_acc)\n",
    "dev_predicted = gs.predict(Xdev)\n",
    "print(\"Accuracy:\", accuracy_score(ydev, dev_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5066dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.71\n",
      "Recall: 0.94\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, _ = precision_recall_fscore_support(ydev, dev_predicted,\n",
    "                                                               average='binary')\n",
    "print(\"Precision:\", np.round(precision, 2))\n",
    "print(\"Recall:\", np.round(recall, 2))\n",
    "# print(\"F-Score:\", np.round(fscore, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17d87c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1 score:  0.8665759383047139\n",
      "Micro f1 score:  0.89\n",
      "Weighted f1 score:  0.8945282792298763\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro f1 score: \",f1_score(ydev, dev_predicted, average='macro'))\n",
    "print(\"Micro f1 score: \",f1_score(ydev, dev_predicted, average='micro'))\n",
    "print(\"Weighted f1 score: \",f1_score(ydev, dev_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc695682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(ydev, dev_predicted)\n",
    "print(\"\\nConfusion Matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88fff013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocess(filename):\n",
    "    header = [\"test_id\", \"Sentence_1\", \"Sentence_2\"]\n",
    "    df = pd.read_csv(filename, quoting=3, encoding='utf8', error_bad_lines=False, names=header,\n",
    "                     sep='\\t')\n",
    "    # Make all words lowercase\n",
    "    df['Sentence_1'] = df['Sentence_1'].str.lower()\n",
    "    df['Sentence_2'] = df['Sentence_2'].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "010a6766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# test_data = test_preprocess(\"test_without_label.txt\")\n",
    "# Xtest = all_features(test_data[\"Sentence_1\"], test_data[\"Sentence_2\"])\n",
    "# Xoutput = pd.DataFrame()\n",
    "# Xoutput['test_id'] = test_data[\"test_id\"]\n",
    "# Xoutput['prediction'] = gs.predict(Xtest)\n",
    "# Xoutput.to_csv(\"OwenFitzgeraldKing_test_result.txt\", sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
